{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 16 3 0 0 0 0 0\n",
      "200944\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import os\n",
    "# Open the file in binary mode\n",
    "\n",
    "safetensor_file = \"./net.safetensors\"\n",
    "\n",
    "def get_meta_size(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        # Read the first 8 bytes\n",
    "        bytes_data = f.read(8)\n",
    "        # print them as uint8 integers, convert hex to decimal\n",
    "        print(\" \".join([str(x) for x in bytes_data]))\n",
    "        # Unpack the bytes to a 64-bit unsigned integer\n",
    "        meta_size = struct.unpack('Q', bytes_data)[0]\n",
    "        return meta_size\n",
    "\n",
    "print(get_meta_size(safetensor_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.numpy import load_file\n",
    "\n",
    "loaded = load_file(safetensor_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphas_cumprod (1000,) float32 0.003814697265625 MB\n",
      "cond_stage_model.transformer.text_model.embeddings.position_embedding.vocab_counter (1, 1, 77) float32 0.000293731689453125 MB\n",
      "cond_stage_model.transformer.text_model.embeddings.position_embedding.weight (77, 768) float32 0.2255859375 MB\n",
      "cond_stage_model.transformer.text_model.embeddings.token_embedding.vocab_counter (1, 1, 49408) float32 0.1884765625 MB\n",
      "cond_stage_model.transformer.text_model.embeddings.token_embedding.weight (49408, 768) float32 144.75 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.bias (3072,) float32 0.01171875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.weight (3072, 768) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.weight (768, 3072) float32 9.0 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.weight (768, 768) float32 2.25 MB\n",
      "cond_stage_model.transformer.text_model.final_layer_norm.bias (768,) float32 0.0029296875 MB\n",
      "cond_stage_model.transformer.text_model.final_layer_norm.weight (768,) float32 0.0029296875 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.0.bias (16,) float32 6.103515625e-05 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.0.weight (16, 16, 3, 3) float32 0.0087890625 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.1.bias (32,) float32 0.0001220703125 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.1.weight (32, 16, 3, 3) float32 0.017578125 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.2.bias (32,) float32 0.0001220703125 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.2.weight (32, 32, 3, 3) float32 0.03515625 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.3.bias (96,) float32 0.0003662109375 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.3.weight (96, 32, 3, 3) float32 0.10546875 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.4.bias (96,) float32 0.0003662109375 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.4.weight (96, 96, 3, 3) float32 0.31640625 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.5.bias (256,) float32 0.0009765625 MB\n",
      "controlnet.controlnet_cond_embedding.blocks.5.weight (256, 96, 3, 3) float32 0.84375 MB\n",
      "controlnet.controlnet_cond_embedding.conv_in.bias (16,) float32 6.103515625e-05 MB\n",
      "controlnet.controlnet_cond_embedding.conv_in.weight (16, 3, 3, 3) float32 0.00164794921875 MB\n",
      "controlnet.controlnet_cond_embedding.conv_out.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.controlnet_cond_embedding.conv_out.weight (320, 256, 3, 3) float32 2.8125 MB\n",
      "controlnet.controlnet_down_blocks.0.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.controlnet_down_blocks.0.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "controlnet.controlnet_down_blocks.1.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.controlnet_down_blocks.1.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "controlnet.controlnet_down_blocks.10.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.controlnet_down_blocks.10.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.controlnet_down_blocks.11.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.controlnet_down_blocks.11.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.controlnet_down_blocks.2.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.controlnet_down_blocks.2.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "controlnet.controlnet_down_blocks.3.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.controlnet_down_blocks.3.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "controlnet.controlnet_down_blocks.4.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.controlnet_down_blocks.4.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "controlnet.controlnet_down_blocks.5.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.controlnet_down_blocks.5.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "controlnet.controlnet_down_blocks.6.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.controlnet_down_blocks.6.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "controlnet.controlnet_down_blocks.7.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.controlnet_down_blocks.7.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.controlnet_down_blocks.8.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.controlnet_down_blocks.8.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.controlnet_down_blocks.9.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.controlnet_down_blocks.9.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.controlnet_mid_block.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.controlnet_mid_block.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.conv_in.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.conv_in.weight (320, 4, 3, 3) float32 0.0439453125 MB\n",
      "controlnet.down_blocks.0.attentions.0.norm.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.norm.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.proj_in.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.proj_in.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.0.proj_out.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.proj_out.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight (320, 768) float32 0.9375 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight (320, 768) float32 0.9375 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias (2560,) float32 0.009765625 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight (2560, 320) float32 3.125 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight (320, 1280) float32 1.5625 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.norm1.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.norm1.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.norm3.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.0.transformer_blocks.0.norm3.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.norm.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.norm.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.proj_in.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.proj_in.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.1.proj_out.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.proj_out.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight (320, 768) float32 0.9375 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight (320, 320) float32 0.390625 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight (320, 768) float32 0.9375 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias (2560,) float32 0.009765625 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight (2560, 320) float32 3.125 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight (320, 1280) float32 1.5625 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.norm1.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.norm1.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.norm3.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.attentions.1.transformer_blocks.0.norm3.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.downsamplers.0.conv.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.downsamplers.0.conv.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "controlnet.down_blocks.0.resnets.0.conv1.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.0.conv1.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "controlnet.down_blocks.0.resnets.0.conv2.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.0.conv2.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "controlnet.down_blocks.0.resnets.0.norm1.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.0.norm1.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.0.norm2.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.0.norm2.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.0.time_emb_proj.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.0.time_emb_proj.weight (320, 1280) float32 1.5625 MB\n",
      "controlnet.down_blocks.0.resnets.1.conv1.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.1.conv1.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "controlnet.down_blocks.0.resnets.1.conv2.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.1.conv2.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "controlnet.down_blocks.0.resnets.1.norm1.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.1.norm1.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.1.norm2.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.1.norm2.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.1.time_emb_proj.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.0.resnets.1.time_emb_proj.weight (320, 1280) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.0.norm.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.norm.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.proj_in.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.proj_in.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.0.proj_out.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.proj_out.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight (640, 768) float32 1.875 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight (640, 768) float32 1.875 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias (5120,) float32 0.01953125 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight (5120, 640) float32 12.5 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight (640, 2560) float32 6.25 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.norm.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.norm.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.proj_in.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.proj_in.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.1.proj_out.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.proj_out.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight (640, 768) float32 1.875 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight (640, 640) float32 1.5625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight (640, 768) float32 1.875 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias (5120,) float32 0.01953125 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight (5120, 640) float32 12.5 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight (640, 2560) float32 6.25 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.downsamplers.0.conv.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.downsamplers.0.conv.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "controlnet.down_blocks.1.resnets.0.conv1.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.0.conv1.weight (640, 320, 3, 3) float32 7.03125 MB\n",
      "controlnet.down_blocks.1.resnets.0.conv2.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.0.conv2.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "controlnet.down_blocks.1.resnets.0.conv_shortcut.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.0.conv_shortcut.weight (640, 320, 1, 1) float32 0.78125 MB\n",
      "controlnet.down_blocks.1.resnets.0.norm1.bias (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.1.resnets.0.norm1.weight (320,) float32 0.001220703125 MB\n",
      "controlnet.down_blocks.1.resnets.0.norm2.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.0.norm2.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.0.time_emb_proj.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.0.time_emb_proj.weight (640, 1280) float32 3.125 MB\n",
      "controlnet.down_blocks.1.resnets.1.conv1.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.1.conv1.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "controlnet.down_blocks.1.resnets.1.conv2.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.1.conv2.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "controlnet.down_blocks.1.resnets.1.norm1.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.1.norm1.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.1.norm2.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.1.norm2.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.1.time_emb_proj.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.1.resnets.1.time_emb_proj.weight (640, 1280) float32 3.125 MB\n",
      "controlnet.down_blocks.2.attentions.0.norm.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.norm.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.proj_in.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.proj_in.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.0.proj_out.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.proj_out.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight (1280, 768) float32 3.75 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight (1280, 768) float32 3.75 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias (10240,) float32 0.0390625 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight (10240, 1280) float32 50.0 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight (1280, 5120) float32 25.0 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.norm.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.norm.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.proj_in.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.proj_in.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.1.proj_out.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.proj_out.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight (1280, 768) float32 3.75 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight (1280, 768) float32 3.75 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias (10240,) float32 0.0390625 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight (10240, 1280) float32 50.0 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight (1280, 5120) float32 25.0 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.downsamplers.0.conv.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.downsamplers.0.conv.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.down_blocks.2.resnets.0.conv1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.0.conv1.weight (1280, 640, 3, 3) float32 28.125 MB\n",
      "controlnet.down_blocks.2.resnets.0.conv2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.0.conv2.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.down_blocks.2.resnets.0.conv_shortcut.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.0.conv_shortcut.weight (1280, 640, 1, 1) float32 3.125 MB\n",
      "controlnet.down_blocks.2.resnets.0.norm1.bias (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.2.resnets.0.norm1.weight (640,) float32 0.00244140625 MB\n",
      "controlnet.down_blocks.2.resnets.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.0.time_emb_proj.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.0.time_emb_proj.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.2.resnets.1.conv1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.1.conv1.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.down_blocks.2.resnets.1.conv2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.1.conv2.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.down_blocks.2.resnets.1.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.1.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.1.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.1.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.1.time_emb_proj.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.2.resnets.1.time_emb_proj.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.3.resnets.0.conv1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.0.conv1.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.down_blocks.3.resnets.0.conv2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.0.conv2.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.down_blocks.3.resnets.0.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.0.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.0.time_emb_proj.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.0.time_emb_proj.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.down_blocks.3.resnets.1.conv1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.1.conv1.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.down_blocks.3.resnets.1.conv2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.1.conv2.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.down_blocks.3.resnets.1.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.1.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.1.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.1.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.1.time_emb_proj.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.down_blocks.3.resnets.1.time_emb_proj.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.mid_block.attentions.0.norm.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.norm.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.proj_in.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.proj_in.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.mid_block.attentions.0.proj_out.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.proj_out.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight (1280, 768) float32 3.75 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight (1280, 768) float32 3.75 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias (10240,) float32 0.0390625 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight (10240, 1280) float32 50.0 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight (1280, 5120) float32 25.0 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.norm3.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.attentions.0.transformer_blocks.0.norm3.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.0.conv1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.0.conv1.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.mid_block.resnets.0.conv2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.0.conv2.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.mid_block.resnets.0.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.0.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.0.time_emb_proj.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.0.time_emb_proj.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.mid_block.resnets.1.conv1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.1.conv1.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.mid_block.resnets.1.conv2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.1.conv2.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "controlnet.mid_block.resnets.1.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.1.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.1.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.1.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.1.time_emb_proj.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.mid_block.resnets.1.time_emb_proj.weight (1280, 1280) float32 6.25 MB\n",
      "controlnet.time_embedding.linear_1.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.time_embedding.linear_1.weight (1280, 320) float32 1.5625 MB\n",
      "controlnet.time_embedding.linear_2.bias (1280,) float32 0.0048828125 MB\n",
      "controlnet.time_embedding.linear_2.weight (1280, 1280) float32 6.25 MB\n",
      "first_stage_model.decoder.conv_in.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.conv_in.weight (512, 4, 3, 3) float32 0.0703125 MB\n",
      "first_stage_model.decoder.conv_out.bias (3,) float32 1.1444091796875e-05 MB\n",
      "first_stage_model.decoder.conv_out.weight (3, 128, 3, 3) float32 0.01318359375 MB\n",
      "first_stage_model.decoder.mid.attn_1.k.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.attn_1.k.weight (512, 512, 1, 1) float32 1.0 MB\n",
      "first_stage_model.decoder.mid.attn_1.norm.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.attn_1.norm.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.attn_1.proj_out.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.attn_1.proj_out.weight (512, 512, 1, 1) float32 1.0 MB\n",
      "first_stage_model.decoder.mid.attn_1.q.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.attn_1.q.weight (512, 512, 1, 1) float32 1.0 MB\n",
      "first_stage_model.decoder.mid.attn_1.v.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.attn_1.v.weight (512, 512, 1, 1) float32 1.0 MB\n",
      "first_stage_model.decoder.mid.block_1.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.block_1.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.mid.block_1.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.block_1.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.mid.block_1.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.block_1.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.block_1.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.block_1.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.block_2.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.block_2.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.mid.block_2.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.block_2.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.mid.block_2.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.block_2.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.block_2.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.mid.block_2.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.norm_out.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.norm_out.weight (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.0.conv1.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.0.conv1.weight (128, 256, 3, 3) float32 1.125 MB\n",
      "first_stage_model.decoder.up.0.block.0.conv2.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.0.conv2.weight (128, 128, 3, 3) float32 0.5625 MB\n",
      "first_stage_model.decoder.up.0.block.0.nin_shortcut.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.0.nin_shortcut.weight (128, 256, 1, 1) float32 0.125 MB\n",
      "first_stage_model.decoder.up.0.block.0.norm1.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.0.block.0.norm1.weight (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.0.block.0.norm2.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.0.norm2.weight (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.1.conv1.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.1.conv1.weight (128, 128, 3, 3) float32 0.5625 MB\n",
      "first_stage_model.decoder.up.0.block.1.conv2.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.1.conv2.weight (128, 128, 3, 3) float32 0.5625 MB\n",
      "first_stage_model.decoder.up.0.block.1.norm1.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.1.norm1.weight (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.1.norm2.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.1.norm2.weight (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.2.conv1.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.2.conv1.weight (128, 128, 3, 3) float32 0.5625 MB\n",
      "first_stage_model.decoder.up.0.block.2.conv2.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.2.conv2.weight (128, 128, 3, 3) float32 0.5625 MB\n",
      "first_stage_model.decoder.up.0.block.2.norm1.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.2.norm1.weight (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.2.norm2.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.0.block.2.norm2.weight (128,) float32 0.00048828125 MB\n",
      "first_stage_model.decoder.up.1.block.0.conv1.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.0.conv1.weight (256, 512, 3, 3) float32 4.5 MB\n",
      "first_stage_model.decoder.up.1.block.0.conv2.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.0.conv2.weight (256, 256, 3, 3) float32 2.25 MB\n",
      "first_stage_model.decoder.up.1.block.0.nin_shortcut.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.0.nin_shortcut.weight (256, 512, 1, 1) float32 0.5 MB\n",
      "first_stage_model.decoder.up.1.block.0.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.1.block.0.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.1.block.0.norm2.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.0.norm2.weight (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.1.conv1.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.1.conv1.weight (256, 256, 3, 3) float32 2.25 MB\n",
      "first_stage_model.decoder.up.1.block.1.conv2.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.1.conv2.weight (256, 256, 3, 3) float32 2.25 MB\n",
      "first_stage_model.decoder.up.1.block.1.norm1.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.1.norm1.weight (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.1.norm2.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.1.norm2.weight (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.2.conv1.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.2.conv1.weight (256, 256, 3, 3) float32 2.25 MB\n",
      "first_stage_model.decoder.up.1.block.2.conv2.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.2.conv2.weight (256, 256, 3, 3) float32 2.25 MB\n",
      "first_stage_model.decoder.up.1.block.2.norm1.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.2.norm1.weight (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.2.norm2.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.block.2.norm2.weight (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.upsample.conv.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.decoder.up.1.upsample.conv.weight (256, 256, 3, 3) float32 2.25 MB\n",
      "first_stage_model.decoder.up.2.block.0.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.0.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.2.block.0.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.0.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.2.block.0.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.0.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.0.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.0.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.1.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.1.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.2.block.1.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.1.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.2.block.1.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.1.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.1.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.1.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.2.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.2.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.2.block.2.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.2.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.2.block.2.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.2.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.2.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.block.2.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.upsample.conv.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.2.upsample.conv.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.3.block.0.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.0.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.3.block.0.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.0.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.3.block.0.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.0.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.0.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.0.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.1.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.1.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.3.block.1.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.1.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.3.block.1.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.1.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.1.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.1.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.2.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.2.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.3.block.2.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.2.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.decoder.up.3.block.2.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.2.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.2.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.block.2.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.upsample.conv.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.decoder.up.3.upsample.conv.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.conv_in.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.conv_in.weight (128, 3, 3, 3) float32 0.01318359375 MB\n",
      "first_stage_model.encoder.conv_out.bias (8,) float32 3.0517578125e-05 MB\n",
      "first_stage_model.encoder.conv_out.weight (8, 512, 3, 3) float32 0.140625 MB\n",
      "first_stage_model.encoder.down.0.block.0.conv1.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.block.0.conv1.weight (128, 128, 3, 3) float32 0.5625 MB\n",
      "first_stage_model.encoder.down.0.block.0.conv2.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.block.0.conv2.weight (128, 128, 3, 3) float32 0.5625 MB\n",
      "first_stage_model.encoder.down.0.block.0.norm1.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.block.0.norm1.weight (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.block.0.norm2.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.block.0.norm2.weight (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.block.1.conv1.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.block.1.conv1.weight (128, 128, 3, 3) float32 0.5625 MB\n",
      "first_stage_model.encoder.down.0.block.1.conv2.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.block.1.conv2.weight (128, 128, 3, 3) float32 0.5625 MB\n",
      "first_stage_model.encoder.down.0.block.1.norm1.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.block.1.norm1.weight (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.block.1.norm2.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.block.1.norm2.weight (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.downsample.conv.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.0.downsample.conv.weight (128, 128, 3, 3) float32 0.5625 MB\n",
      "first_stage_model.encoder.down.1.block.0.conv1.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.block.0.conv1.weight (256, 128, 3, 3) float32 1.125 MB\n",
      "first_stage_model.encoder.down.1.block.0.conv2.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.block.0.conv2.weight (256, 256, 3, 3) float32 2.25 MB\n",
      "first_stage_model.encoder.down.1.block.0.nin_shortcut.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.block.0.nin_shortcut.weight (256, 128, 1, 1) float32 0.125 MB\n",
      "first_stage_model.encoder.down.1.block.0.norm1.bias (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.1.block.0.norm1.weight (128,) float32 0.00048828125 MB\n",
      "first_stage_model.encoder.down.1.block.0.norm2.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.block.0.norm2.weight (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.block.1.conv1.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.block.1.conv1.weight (256, 256, 3, 3) float32 2.25 MB\n",
      "first_stage_model.encoder.down.1.block.1.conv2.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.block.1.conv2.weight (256, 256, 3, 3) float32 2.25 MB\n",
      "first_stage_model.encoder.down.1.block.1.norm1.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.block.1.norm1.weight (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.block.1.norm2.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.block.1.norm2.weight (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.downsample.conv.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.1.downsample.conv.weight (256, 256, 3, 3) float32 2.25 MB\n",
      "first_stage_model.encoder.down.2.block.0.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.block.0.conv1.weight (512, 256, 3, 3) float32 4.5 MB\n",
      "first_stage_model.encoder.down.2.block.0.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.block.0.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.down.2.block.0.nin_shortcut.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.block.0.nin_shortcut.weight (512, 256, 1, 1) float32 0.5 MB\n",
      "first_stage_model.encoder.down.2.block.0.norm1.bias (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.2.block.0.norm1.weight (256,) float32 0.0009765625 MB\n",
      "first_stage_model.encoder.down.2.block.0.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.block.0.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.block.1.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.block.1.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.down.2.block.1.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.block.1.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.down.2.block.1.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.block.1.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.block.1.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.block.1.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.downsample.conv.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.2.downsample.conv.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.down.3.block.0.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.3.block.0.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.down.3.block.0.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.3.block.0.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.down.3.block.0.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.3.block.0.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.3.block.0.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.3.block.0.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.3.block.1.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.3.block.1.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.down.3.block.1.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.3.block.1.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.down.3.block.1.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.3.block.1.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.3.block.1.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.down.3.block.1.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.attn_1.k.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.attn_1.k.weight (512, 512, 1, 1) float32 1.0 MB\n",
      "first_stage_model.encoder.mid.attn_1.norm.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.attn_1.norm.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.attn_1.proj_out.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.attn_1.proj_out.weight (512, 512, 1, 1) float32 1.0 MB\n",
      "first_stage_model.encoder.mid.attn_1.q.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.attn_1.q.weight (512, 512, 1, 1) float32 1.0 MB\n",
      "first_stage_model.encoder.mid.attn_1.v.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.attn_1.v.weight (512, 512, 1, 1) float32 1.0 MB\n",
      "first_stage_model.encoder.mid.block_1.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.block_1.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.mid.block_1.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.block_1.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.mid.block_1.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.block_1.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.block_1.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.block_1.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.block_2.conv1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.block_2.conv1.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.mid.block_2.conv2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.block_2.conv2.weight (512, 512, 3, 3) float32 9.0 MB\n",
      "first_stage_model.encoder.mid.block_2.norm1.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.block_2.norm1.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.block_2.norm2.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.mid.block_2.norm2.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.norm_out.bias (512,) float32 0.001953125 MB\n",
      "first_stage_model.encoder.norm_out.weight (512,) float32 0.001953125 MB\n",
      "first_stage_model.post_quant_conv.bias (4,) float32 1.52587890625e-05 MB\n",
      "first_stage_model.post_quant_conv.weight (4, 4, 1, 1) float32 6.103515625e-05 MB\n",
      "first_stage_model.quant_conv.bias (8,) float32 3.0517578125e-05 MB\n",
      "first_stage_model.quant_conv.weight (8, 8, 1, 1) float32 0.000244140625 MB\n",
      "model.diffusion_model.input_blocks.0.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.0.0.weight (320, 4, 3, 3) float32 0.0439453125 MB\n",
      "model.diffusion_model.input_blocks.1.0.emb_layers.1.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.0.emb_layers.1.weight (320, 1280) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.1.0.in_layers.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.0.in_layers.0.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.0.in_layers.2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.0.in_layers.2.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "model.diffusion_model.input_blocks.1.0.out_layers.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.0.out_layers.0.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.0.out_layers.3.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.0.out_layers.3.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "model.diffusion_model.input_blocks.1.1.norm.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.norm.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.proj_in.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.proj_in.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.1.1.proj_out.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.proj_out.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight (320, 768) float32 0.9375 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight (320, 768) float32 0.9375 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight (2560, 320) float32 3.125 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight (320, 1280) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.10.0.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.10.0.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.10.0.in_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.10.0.in_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.10.0.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.10.0.in_layers.2.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.input_blocks.10.0.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.10.0.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.10.0.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.10.0.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.input_blocks.11.0.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.11.0.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.11.0.in_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.11.0.in_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.11.0.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.11.0.in_layers.2.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.input_blocks.11.0.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.11.0.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.11.0.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.11.0.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.input_blocks.2.0.emb_layers.1.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.0.emb_layers.1.weight (320, 1280) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.2.0.in_layers.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.0.in_layers.0.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.0.in_layers.2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.0.in_layers.2.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "model.diffusion_model.input_blocks.2.0.out_layers.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.0.out_layers.0.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.0.out_layers.3.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.0.out_layers.3.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "model.diffusion_model.input_blocks.2.1.norm.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.norm.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.proj_in.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.proj_in.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.2.1.proj_out.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.proj_out.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight (320, 768) float32 0.9375 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight (320, 768) float32 0.9375 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight (2560, 320) float32 3.125 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight (320, 1280) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.3.0.op.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.3.0.op.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "model.diffusion_model.input_blocks.4.0.emb_layers.1.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.0.emb_layers.1.weight (640, 1280) float32 3.125 MB\n",
      "model.diffusion_model.input_blocks.4.0.in_layers.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.4.0.in_layers.0.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.input_blocks.4.0.in_layers.2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.0.in_layers.2.weight (640, 320, 3, 3) float32 7.03125 MB\n",
      "model.diffusion_model.input_blocks.4.0.out_layers.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.0.out_layers.0.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.0.out_layers.3.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.0.out_layers.3.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "model.diffusion_model.input_blocks.4.0.skip_connection.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.0.skip_connection.weight (640, 320, 1, 1) float32 0.78125 MB\n",
      "model.diffusion_model.input_blocks.4.1.norm.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.norm.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.proj_in.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.proj_in.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.4.1.proj_out.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.proj_out.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight (640, 768) float32 1.875 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight (640, 768) float32 1.875 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias (5120,) float32 0.01953125 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight (5120, 640) float32 12.5 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight (640, 2560) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.0.emb_layers.1.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.0.emb_layers.1.weight (640, 1280) float32 3.125 MB\n",
      "model.diffusion_model.input_blocks.5.0.in_layers.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.0.in_layers.0.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.0.in_layers.2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.0.in_layers.2.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "model.diffusion_model.input_blocks.5.0.out_layers.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.0.out_layers.0.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.0.out_layers.3.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.0.out_layers.3.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "model.diffusion_model.input_blocks.5.1.norm.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.norm.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.proj_in.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.proj_in.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.5.1.proj_out.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.proj_out.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight (640, 768) float32 1.875 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight (640, 768) float32 1.875 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias (5120,) float32 0.01953125 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight (5120, 640) float32 12.5 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight (640, 2560) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.6.0.op.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.6.0.op.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "model.diffusion_model.input_blocks.7.0.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.0.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.7.0.in_layers.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.7.0.in_layers.0.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.input_blocks.7.0.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.0.in_layers.2.weight (1280, 640, 3, 3) float32 28.125 MB\n",
      "model.diffusion_model.input_blocks.7.0.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.0.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.0.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.0.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.input_blocks.7.0.skip_connection.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.0.skip_connection.weight (1280, 640, 1, 1) float32 3.125 MB\n",
      "model.diffusion_model.input_blocks.7.1.norm.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.norm.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.proj_in.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.proj_in.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.7.1.proj_out.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.proj_out.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias (10240,) float32 0.0390625 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight (10240, 1280) float32 50.0 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight (1280, 5120) float32 25.0 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.0.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.0.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.8.0.in_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.0.in_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.0.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.0.in_layers.2.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.input_blocks.8.0.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.0.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.0.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.0.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.input_blocks.8.1.norm.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.norm.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.proj_in.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.proj_in.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.8.1.proj_out.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.proj_out.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias (10240,) float32 0.0390625 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight (10240, 1280) float32 50.0 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight (1280, 5120) float32 25.0 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.9.0.op.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.input_blocks.9.0.op.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.middle_block.0.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.0.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.middle_block.0.in_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.0.in_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.0.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.0.in_layers.2.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.middle_block.0.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.0.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.0.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.0.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.middle_block.1.norm.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.norm.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.proj_in.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.proj_in.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.middle_block.1.proj_out.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.proj_out.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias (10240,) float32 0.0390625 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight (10240, 1280) float32 50.0 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight (1280, 5120) float32 25.0 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.2.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.2.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.middle_block.2.in_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.2.in_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.2.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.2.in_layers.2.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.middle_block.2.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.2.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.2.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.middle_block.2.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.out.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.out.0.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.out.2.bias (4,) float32 1.52587890625e-05 MB\n",
      "model.diffusion_model.out.2.weight (4, 320, 3, 3) float32 0.0439453125 MB\n",
      "model.diffusion_model.output_blocks.0.0.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.0.0.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.0.0.in_layers.0.bias (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.0.0.in_layers.0.weight (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.0.0.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.0.0.in_layers.2.weight (1280, 2560, 3, 3) float32 112.5 MB\n",
      "model.diffusion_model.output_blocks.0.0.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.0.0.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.0.0.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.0.0.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.output_blocks.0.0.skip_connection.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.0.0.skip_connection.weight (1280, 2560, 1, 1) float32 12.5 MB\n",
      "model.diffusion_model.output_blocks.1.0.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.1.0.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.1.0.in_layers.0.bias (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.1.0.in_layers.0.weight (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.1.0.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.1.0.in_layers.2.weight (1280, 2560, 3, 3) float32 112.5 MB\n",
      "model.diffusion_model.output_blocks.1.0.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.1.0.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.1.0.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.1.0.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.output_blocks.1.0.skip_connection.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.1.0.skip_connection.weight (1280, 2560, 1, 1) float32 12.5 MB\n",
      "model.diffusion_model.output_blocks.10.0.emb_layers.1.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.0.emb_layers.1.weight (320, 1280) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.10.0.in_layers.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.10.0.in_layers.0.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.10.0.in_layers.2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.0.in_layers.2.weight (320, 640, 3, 3) float32 7.03125 MB\n",
      "model.diffusion_model.output_blocks.10.0.out_layers.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.0.out_layers.0.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.0.out_layers.3.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.0.out_layers.3.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "model.diffusion_model.output_blocks.10.0.skip_connection.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.0.skip_connection.weight (320, 640, 1, 1) float32 0.78125 MB\n",
      "model.diffusion_model.output_blocks.10.1.norm.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.norm.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.proj_in.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.proj_in.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.10.1.proj_out.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.proj_out.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight (320, 768) float32 0.9375 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight (320, 768) float32 0.9375 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight (2560, 320) float32 3.125 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight (320, 1280) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.0.emb_layers.1.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.0.emb_layers.1.weight (320, 1280) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.11.0.in_layers.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.11.0.in_layers.0.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.11.0.in_layers.2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.0.in_layers.2.weight (320, 640, 3, 3) float32 7.03125 MB\n",
      "model.diffusion_model.output_blocks.11.0.out_layers.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.0.out_layers.0.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.0.out_layers.3.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.0.out_layers.3.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "model.diffusion_model.output_blocks.11.0.skip_connection.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.0.skip_connection.weight (320, 640, 1, 1) float32 0.78125 MB\n",
      "model.diffusion_model.output_blocks.11.1.norm.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.norm.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.proj_in.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.proj_in.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.11.1.proj_out.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.proj_out.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight (320, 768) float32 0.9375 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight (320, 768) float32 0.9375 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight (2560, 320) float32 3.125 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight (320, 1280) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.2.0.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.2.0.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.2.0.in_layers.0.bias (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.2.0.in_layers.0.weight (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.2.0.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.2.0.in_layers.2.weight (1280, 2560, 3, 3) float32 112.5 MB\n",
      "model.diffusion_model.output_blocks.2.0.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.2.0.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.2.0.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.2.0.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.output_blocks.2.0.skip_connection.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.2.0.skip_connection.weight (1280, 2560, 1, 1) float32 12.5 MB\n",
      "model.diffusion_model.output_blocks.2.1.conv.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.2.1.conv.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.output_blocks.3.0.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.0.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.3.0.in_layers.0.bias (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.3.0.in_layers.0.weight (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.3.0.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.0.in_layers.2.weight (1280, 2560, 3, 3) float32 112.5 MB\n",
      "model.diffusion_model.output_blocks.3.0.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.0.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.0.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.0.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.output_blocks.3.0.skip_connection.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.0.skip_connection.weight (1280, 2560, 1, 1) float32 12.5 MB\n",
      "model.diffusion_model.output_blocks.3.1.norm.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.norm.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.proj_in.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.proj_in.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.3.1.proj_out.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.proj_out.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias (10240,) float32 0.0390625 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight (10240, 1280) float32 50.0 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight (1280, 5120) float32 25.0 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.0.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.0.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.4.0.in_layers.0.bias (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.4.0.in_layers.0.weight (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.4.0.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.0.in_layers.2.weight (1280, 2560, 3, 3) float32 112.5 MB\n",
      "model.diffusion_model.output_blocks.4.0.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.0.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.0.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.0.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.output_blocks.4.0.skip_connection.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.0.skip_connection.weight (1280, 2560, 1, 1) float32 12.5 MB\n",
      "model.diffusion_model.output_blocks.4.1.norm.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.norm.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.proj_in.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.proj_in.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.4.1.proj_out.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.proj_out.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias (10240,) float32 0.0390625 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight (10240, 1280) float32 50.0 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight (1280, 5120) float32 25.0 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.0.emb_layers.1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.0.emb_layers.1.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.5.0.in_layers.0.bias (1920,) float32 0.00732421875 MB\n",
      "model.diffusion_model.output_blocks.5.0.in_layers.0.weight (1920,) float32 0.00732421875 MB\n",
      "model.diffusion_model.output_blocks.5.0.in_layers.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.0.in_layers.2.weight (1280, 1920, 3, 3) float32 84.375 MB\n",
      "model.diffusion_model.output_blocks.5.0.out_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.0.out_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.0.out_layers.3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.0.out_layers.3.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.output_blocks.5.0.skip_connection.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.0.skip_connection.weight (1280, 1920, 1, 1) float32 9.375 MB\n",
      "model.diffusion_model.output_blocks.5.1.norm.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.norm.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.proj_in.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.proj_in.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.5.1.proj_out.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.proj_out.weight (1280, 1280, 1, 1) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight (1280, 1280) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight (1280, 768) float32 3.75 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias (10240,) float32 0.0390625 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight (10240, 1280) float32 50.0 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight (1280, 5120) float32 25.0 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.2.conv.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.5.2.conv.weight (1280, 1280, 3, 3) float32 56.25 MB\n",
      "model.diffusion_model.output_blocks.6.0.emb_layers.1.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.0.emb_layers.1.weight (640, 1280) float32 3.125 MB\n",
      "model.diffusion_model.output_blocks.6.0.in_layers.0.bias (1920,) float32 0.00732421875 MB\n",
      "model.diffusion_model.output_blocks.6.0.in_layers.0.weight (1920,) float32 0.00732421875 MB\n",
      "model.diffusion_model.output_blocks.6.0.in_layers.2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.0.in_layers.2.weight (640, 1920, 3, 3) float32 42.1875 MB\n",
      "model.diffusion_model.output_blocks.6.0.out_layers.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.0.out_layers.0.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.0.out_layers.3.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.0.out_layers.3.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "model.diffusion_model.output_blocks.6.0.skip_connection.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.0.skip_connection.weight (640, 1920, 1, 1) float32 4.6875 MB\n",
      "model.diffusion_model.output_blocks.6.1.norm.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.norm.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.proj_in.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.proj_in.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.6.1.proj_out.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.proj_out.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight (640, 768) float32 1.875 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight (640, 768) float32 1.875 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias (5120,) float32 0.01953125 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight (5120, 640) float32 12.5 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight (640, 2560) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.0.emb_layers.1.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.0.emb_layers.1.weight (640, 1280) float32 3.125 MB\n",
      "model.diffusion_model.output_blocks.7.0.in_layers.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.7.0.in_layers.0.weight (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.output_blocks.7.0.in_layers.2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.0.in_layers.2.weight (640, 1280, 3, 3) float32 28.125 MB\n",
      "model.diffusion_model.output_blocks.7.0.out_layers.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.0.out_layers.0.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.0.out_layers.3.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.0.out_layers.3.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "model.diffusion_model.output_blocks.7.0.skip_connection.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.0.skip_connection.weight (640, 1280, 1, 1) float32 3.125 MB\n",
      "model.diffusion_model.output_blocks.7.1.norm.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.norm.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.proj_in.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.proj_in.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.7.1.proj_out.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.proj_out.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight (640, 768) float32 1.875 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight (640, 768) float32 1.875 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias (5120,) float32 0.01953125 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight (5120, 640) float32 12.5 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight (640, 2560) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.0.emb_layers.1.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.0.emb_layers.1.weight (640, 1280) float32 3.125 MB\n",
      "model.diffusion_model.output_blocks.8.0.in_layers.0.bias (960,) float32 0.003662109375 MB\n",
      "model.diffusion_model.output_blocks.8.0.in_layers.0.weight (960,) float32 0.003662109375 MB\n",
      "model.diffusion_model.output_blocks.8.0.in_layers.2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.0.in_layers.2.weight (640, 960, 3, 3) float32 21.09375 MB\n",
      "model.diffusion_model.output_blocks.8.0.out_layers.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.0.out_layers.0.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.0.out_layers.3.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.0.out_layers.3.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "model.diffusion_model.output_blocks.8.0.skip_connection.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.0.skip_connection.weight (640, 960, 1, 1) float32 2.34375 MB\n",
      "model.diffusion_model.output_blocks.8.1.norm.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.norm.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.proj_in.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.proj_in.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.8.1.proj_out.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.proj_out.weight (640, 640, 1, 1) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight (640, 768) float32 1.875 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight (640, 640) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight (640, 768) float32 1.875 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias (5120,) float32 0.01953125 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight (5120, 640) float32 12.5 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight (640, 2560) float32 6.25 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.2.conv.bias (640,) float32 0.00244140625 MB\n",
      "model.diffusion_model.output_blocks.8.2.conv.weight (640, 640, 3, 3) float32 14.0625 MB\n",
      "model.diffusion_model.output_blocks.9.0.emb_layers.1.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.0.emb_layers.1.weight (320, 1280) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.9.0.in_layers.0.bias (960,) float32 0.003662109375 MB\n",
      "model.diffusion_model.output_blocks.9.0.in_layers.0.weight (960,) float32 0.003662109375 MB\n",
      "model.diffusion_model.output_blocks.9.0.in_layers.2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.0.in_layers.2.weight (320, 960, 3, 3) float32 10.546875 MB\n",
      "model.diffusion_model.output_blocks.9.0.out_layers.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.0.out_layers.0.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.0.out_layers.3.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.0.out_layers.3.weight (320, 320, 3, 3) float32 3.515625 MB\n",
      "model.diffusion_model.output_blocks.9.0.skip_connection.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.0.skip_connection.weight (320, 960, 1, 1) float32 1.171875 MB\n",
      "model.diffusion_model.output_blocks.9.1.norm.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.norm.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.proj_in.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.proj_in.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.9.1.proj_out.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.proj_out.weight (320, 320, 1, 1) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight (320, 768) float32 0.9375 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight (320, 320) float32 0.390625 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight (320, 768) float32 0.9375 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias (2560,) float32 0.009765625 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight (2560, 320) float32 3.125 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight (320, 1280) float32 1.5625 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight (320,) float32 0.001220703125 MB\n",
      "model.diffusion_model.time_embed.0.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.time_embed.0.weight (1280, 320) float32 1.5625 MB\n",
      "model.diffusion_model.time_embed.2.bias (1280,) float32 0.0048828125 MB\n",
      "model.diffusion_model.time_embed.2.weight (1280, 1280) float32 6.25 MB\n",
      "Max weight size: 144.75 MB\n"
     ]
    }
   ],
   "source": [
    "# for ech k, v, print the size of v in megabytes\n",
    "max_weight_size = 0\n",
    "for k, v in loaded.items():\n",
    "    print(k, v.shape, v.dtype, v.nbytes / 1024 / 1024, \"MB\")\n",
    "    max_weight_size = max(max_weight_size, v.nbytes / 1024 / 1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99915   , 0.998296  , 0.9974381 , 0.9965762 , 0.99571025,\n",
       "       0.9948404 , 0.9939665 , 0.9930887 , 0.9922069 , 0.9913211 ,\n",
       "       0.9904313 , 0.98953754, 0.9886398 , 0.9877381 , 0.9868324 ,\n",
       "       0.98592263, 0.98500896, 0.9840913 , 0.9831696 , 0.982244  ,\n",
       "       0.98131436, 0.9803808 , 0.97944313, 0.97850156, 0.977556  ,\n",
       "       0.9766064 , 0.97565293, 0.9746954 , 0.9737339 , 0.9727684 ,\n",
       "       0.97179896, 0.97082555, 0.96984816, 0.96886677, 0.9678814 ,\n",
       "       0.96689206, 0.96589875, 0.9649015 , 0.96390027, 0.9628951 ,\n",
       "       0.9618859 , 0.96087277, 0.95985574, 0.95883465, 0.9578097 ,\n",
       "       0.95678073, 0.95574784, 0.954711  , 0.95367026, 0.9526256 ,\n",
       "       0.9515769 , 0.95052433, 0.94946784, 0.94840735, 0.947343  ,\n",
       "       0.94627476, 0.9452025 , 0.9441264 , 0.9430464 , 0.9419625 ,\n",
       "       0.9408747 , 0.939783  , 0.9386874 , 0.93758786, 0.9364845 ,\n",
       "       0.93537724, 0.9342661 , 0.9331511 , 0.9320323 , 0.9309096 ,\n",
       "       0.929783  , 0.9286526 , 0.9275183 , 0.9263802 , 0.92523825,\n",
       "       0.92409253, 0.92294294, 0.9217895 , 0.92063236, 0.9194713 ,\n",
       "       0.9183065 , 0.9171379 , 0.91596556, 0.9147894 , 0.9136095 ,\n",
       "       0.91242576, 0.9112383 , 0.9100471 , 0.9088522 , 0.9076535 ,\n",
       "       0.9064511 , 0.90524495, 0.9040351 , 0.90282154, 0.9016043 ,\n",
       "       0.90038335, 0.8991587 , 0.8979304 , 0.8966984 , 0.89546275,\n",
       "       0.89422345, 0.8929805 , 0.89173394, 0.89048374, 0.88922995,\n",
       "       0.8879725 , 0.8867115 , 0.88544685, 0.88417864, 0.88290685,\n",
       "       0.8816315 , 0.88035256, 0.8790701 , 0.87778413, 0.8764946 ,\n",
       "       0.8752016 , 0.873905  , 0.87260497, 0.8713014 , 0.8699944 ,\n",
       "       0.86868393, 0.86737   , 0.8660526 , 0.8647318 , 0.86340755,\n",
       "       0.8620799 , 0.8607488 , 0.85941434, 0.8580765 , 0.8567353 ,\n",
       "       0.8553907 , 0.8540428 , 0.85269153, 0.85133696, 0.84997904,\n",
       "       0.84861785, 0.8472533 , 0.8458856 , 0.8445145 , 0.84314024,\n",
       "       0.84176266, 0.8403819 , 0.8389979 , 0.8376107 , 0.8362203 ,\n",
       "       0.83482677, 0.83343   , 0.8320301 , 0.8306271 , 0.8292209 ,\n",
       "       0.82781166, 0.82639927, 0.8249838 , 0.82356524, 0.8221436 ,\n",
       "       0.82071894, 0.81929123, 0.81786054, 0.8164268 , 0.8149901 ,\n",
       "       0.8135504 , 0.81210774, 0.81066215, 0.8092136 , 0.8077621 ,\n",
       "       0.80630773, 0.80485046, 0.8033903 , 0.80192727, 0.8004614 ,\n",
       "       0.79899275, 0.79752123, 0.7960469 , 0.7945698 , 0.7930899 ,\n",
       "       0.79160726, 0.7901219 , 0.7886338 , 0.787143  , 0.7856495 ,\n",
       "       0.7841533 , 0.78265446, 0.78115296, 0.7796488 , 0.77814204,\n",
       "       0.7766327 , 0.7751208 , 0.7736063 , 0.77208924, 0.7705697 ,\n",
       "       0.7690476 , 0.767523  , 0.7659959 , 0.7644664 , 0.76293445,\n",
       "       0.7614    , 0.7598632 , 0.75832397, 0.75678235, 0.75523835,\n",
       "       0.75369203, 0.7521434 , 0.75059247, 0.7490392 , 0.7474837 ,\n",
       "       0.7459259 , 0.7443659 , 0.74280363, 0.7412392 , 0.7396726 ,\n",
       "       0.7381038 , 0.73653287, 0.7349598 , 0.7333846 , 0.73180735,\n",
       "       0.730228  , 0.7286466 , 0.7270631 , 0.7254777 , 0.72389024,\n",
       "       0.72230077, 0.7207094 , 0.71911603, 0.7175208 , 0.7159236 ,\n",
       "       0.71432453, 0.7127236 , 0.71112084, 0.7095162 , 0.7079098 ,\n",
       "       0.7063016 , 0.70469165, 0.70307994, 0.7014665 , 0.69985133,\n",
       "       0.6982345 , 0.696616  , 0.6949958 , 0.69337404, 0.69175065,\n",
       "       0.69012564, 0.6884991 , 0.68687093, 0.6852413 , 0.68361014,\n",
       "       0.6819775 , 0.6803434 , 0.67870784, 0.6770708 , 0.6754324 ,\n",
       "       0.6737926 , 0.67215145, 0.670509  , 0.66886514, 0.66722   ,\n",
       "       0.6655736 , 0.66392595, 0.662277  , 0.6606269 , 0.65897554,\n",
       "       0.657323  , 0.65566933, 0.6540145 , 0.6523586 , 0.6507016 ,\n",
       "       0.6490435 , 0.64738435, 0.6457241 , 0.64406294, 0.6424008 ,\n",
       "       0.64073765, 0.63907355, 0.63740855, 0.6357426 , 0.6340758 ,\n",
       "       0.6324082 , 0.6307397 , 0.6290704 , 0.6274003 , 0.6257294 ,\n",
       "       0.62405777, 0.6223854 , 0.62071234, 0.6190386 , 0.61736417,\n",
       "       0.6156891 , 0.61401343, 0.6123372 , 0.6106603 , 0.6089829 ,\n",
       "       0.607305  , 0.6056265 , 0.6039476 , 0.60226816, 0.6005883 ,\n",
       "       0.598908  , 0.59722733, 0.5955463 , 0.59386486, 0.5921831 ,\n",
       "       0.59050107, 0.5888187 , 0.5871361 , 0.5854532 , 0.5837701 ,\n",
       "       0.5820868 , 0.5804033 , 0.5787197 , 0.5770359 , 0.575352  ,\n",
       "       0.57366806, 0.571984  , 0.5702999 , 0.5686158 , 0.56693166,\n",
       "       0.56524754, 0.5635635 , 0.5618795 , 0.56019557, 0.5585118 ,\n",
       "       0.5568281 , 0.55514455, 0.5534612 , 0.551778  , 0.5500951 ,\n",
       "       0.5484124 , 0.54673   , 0.5450478 , 0.54336596, 0.54168445,\n",
       "       0.54000324, 0.53832245, 0.5366421 , 0.53496206, 0.5332825 ,\n",
       "       0.53160346, 0.5299248 , 0.52824676, 0.5265692 , 0.52489215,\n",
       "       0.5232157 , 0.5215398 , 0.51986456, 0.51818997, 0.51651603,\n",
       "       0.51484275, 0.5131702 , 0.5114983 , 0.5098272 , 0.50815684,\n",
       "       0.5064873 , 0.50481856, 0.50315064, 0.50148356, 0.4998174 ,\n",
       "       0.4981521 , 0.49648774, 0.49482432, 0.49316183, 0.49150035,\n",
       "       0.48983985, 0.4881804 , 0.486522  , 0.48486462, 0.4832084 ,\n",
       "       0.48155323, 0.4798992 , 0.47824633, 0.47659463, 0.4749441 ,\n",
       "       0.47329482, 0.4716468 , 0.47      , 0.46835446, 0.46671024,\n",
       "       0.46506736, 0.4634258 , 0.46178558, 0.46014675, 0.45850933,\n",
       "       0.45687333, 0.45523876, 0.45360568, 0.45197406, 0.45034397,\n",
       "       0.44871536, 0.44708833, 0.44546285, 0.44383895, 0.44221666,\n",
       "       0.440596  , 0.43897697, 0.43735963, 0.43574396, 0.43412998,\n",
       "       0.43251774, 0.43090722, 0.4292985 , 0.42769152, 0.42608637,\n",
       "       0.42448303, 0.4228815 , 0.42128187, 0.4196841 , 0.41808826,\n",
       "       0.4164943 , 0.4149023 , 0.41331223, 0.41172415, 0.41013804,\n",
       "       0.40855396, 0.4069719 , 0.4053919 , 0.40381396, 0.4022381 ,\n",
       "       0.40066436, 0.39909273, 0.39752322, 0.3959559 , 0.39439073,\n",
       "       0.39282778, 0.39126703, 0.3897085 , 0.3881522 , 0.3865982 ,\n",
       "       0.38504648, 0.38349706, 0.38194993, 0.38040516, 0.37886274,\n",
       "       0.37732267, 0.375785  , 0.37424973, 0.37271687, 0.37118647,\n",
       "       0.36965853, 0.36813304, 0.36661002, 0.36508954, 0.36357155,\n",
       "       0.3620561 , 0.36054322, 0.3590329 , 0.35752517, 0.35602003,\n",
       "       0.35451752, 0.35301763, 0.3515204 , 0.3500258 , 0.3485339 ,\n",
       "       0.3470447 , 0.34555823, 0.34407446, 0.34259343, 0.34111515,\n",
       "       0.33963963, 0.33816692, 0.336697  , 0.3352299 , 0.33376563,\n",
       "       0.3323042 , 0.33084565, 0.32938993, 0.32793713, 0.3264872 ,\n",
       "       0.32504022, 0.32359615, 0.32215503, 0.32071686, 0.31928164,\n",
       "       0.31784943, 0.3164202 , 0.314994  , 0.3135708 , 0.31215066,\n",
       "       0.31073356, 0.3093195 , 0.30790854, 0.30650064, 0.30509588,\n",
       "       0.30369422, 0.30229566, 0.30090025, 0.299508  , 0.2981189 ,\n",
       "       0.29673296, 0.29535022, 0.2939707 , 0.29259437, 0.29122123,\n",
       "       0.28985137, 0.28848472, 0.28712133, 0.2857612 , 0.28440437,\n",
       "       0.2830508 , 0.28170055, 0.2803536 , 0.27900997, 0.27766964,\n",
       "       0.27633268, 0.27499905, 0.2736688 , 0.27234194, 0.27101842,\n",
       "       0.2696983 , 0.26838157, 0.26706827, 0.26575837, 0.26445192,\n",
       "       0.26314887, 0.2618493 , 0.26055318, 0.2592605 , 0.25797132,\n",
       "       0.2566856 , 0.2554034 , 0.25412467, 0.25284946, 0.25157773,\n",
       "       0.2503096 , 0.24904492, 0.24778382, 0.24652626, 0.24527225,\n",
       "       0.2440218 , 0.24277493, 0.24153163, 0.24029191, 0.23905578,\n",
       "       0.23782326, 0.23659433, 0.23536903, 0.23414734, 0.23292927,\n",
       "       0.23171483, 0.23050404, 0.22929688, 0.22809339, 0.22689353,\n",
       "       0.22569734, 0.22450483, 0.22331597, 0.2221308 , 0.22094932,\n",
       "       0.21977153, 0.21859743, 0.21742703, 0.21626033, 0.21509734,\n",
       "       0.21393807, 0.21278252, 0.21163069, 0.21048258, 0.20933822,\n",
       "       0.20819758, 0.2070607 , 0.20592754, 0.20479813, 0.20367248,\n",
       "       0.20255059, 0.20143245, 0.20031808, 0.19920748, 0.19810064,\n",
       "       0.19699757, 0.19589828, 0.19480278, 0.19371104, 0.1926231 ,\n",
       "       0.19153893, 0.19045855, 0.18938197, 0.18830918, 0.18724018,\n",
       "       0.18617497, 0.18511358, 0.18405597, 0.18300217, 0.18195218,\n",
       "       0.18090598, 0.1798636 , 0.17882504, 0.17779027, 0.1767593 ,\n",
       "       0.17573217, 0.17470883, 0.1736893 , 0.1726736 , 0.1716617 ,\n",
       "       0.17065361, 0.16964935, 0.1686489 , 0.16765225, 0.16665943,\n",
       "       0.16567042, 0.16468522, 0.16370384, 0.16272627, 0.16175252,\n",
       "       0.16078258, 0.15981644, 0.15885411, 0.1578956 , 0.15694089,\n",
       "       0.15599   , 0.15504292, 0.15409963, 0.15316014, 0.15222447,\n",
       "       0.15129258, 0.1503645 , 0.14944021, 0.14851972, 0.14760303,\n",
       "       0.14669013, 0.14578101, 0.14487568, 0.14397413, 0.14307636,\n",
       "       0.14218238, 0.14129217, 0.14040573, 0.13952307, 0.13864417,\n",
       "       0.13776903, 0.13689767, 0.13603005, 0.13516618, 0.13430607,\n",
       "       0.13344972, 0.1325971 , 0.13174823, 0.1309031 , 0.13006169,\n",
       "       0.12922402, 0.12839006, 0.12755983, 0.12673332, 0.12591052,\n",
       "       0.12509143, 0.12427604, 0.12346435, 0.12265636, 0.12185206,\n",
       "       0.12105144, 0.1202545 , 0.11946124, 0.11867165, 0.11788572,\n",
       "       0.11710346, 0.11632485, 0.11554988, 0.11477857, 0.11401089,\n",
       "       0.11324684, 0.11248643, 0.11172963, 0.11097645, 0.11022688,\n",
       "       0.10948092, 0.10873855, 0.10799977, 0.10726459, 0.10653298,\n",
       "       0.10580494, 0.10508047, 0.10435956, 0.1036422 , 0.10292839,\n",
       "       0.10221813, 0.1015114 , 0.10080819, 0.1001085 , 0.09941233,\n",
       "       0.09871966, 0.0980305 , 0.09734483, 0.09666264, 0.09598393,\n",
       "       0.09530868, 0.09463691, 0.09396859, 0.09330372, 0.09264228,\n",
       "       0.09198428, 0.09132971, 0.09067855, 0.0900308 , 0.08938646,\n",
       "       0.0887455 , 0.08810794, 0.08747375, 0.08684293, 0.08621547,\n",
       "       0.08559138, 0.08497062, 0.08435319, 0.0837391 , 0.08312833,\n",
       "       0.08252087, 0.08191671, 0.08131585, 0.08071827, 0.08012398,\n",
       "       0.07953294, 0.07894517, 0.07836065, 0.07777938, 0.07720133,\n",
       "       0.07662651, 0.07605491, 0.07548651, 0.07492131, 0.0743593 ,\n",
       "       0.07380046, 0.0732448 , 0.07269229, 0.07214294, 0.07159673,\n",
       "       0.07105365, 0.0705137 , 0.06997685, 0.06944311, 0.06891247,\n",
       "       0.06838491, 0.06786042, 0.06733901, 0.06682064, 0.06630533,\n",
       "       0.06579305, 0.0652838 , 0.06477757, 0.06427433, 0.0637741 ,\n",
       "       0.06327686, 0.06278259, 0.06229129, 0.06180295, 0.06131756,\n",
       "       0.0608351 , 0.06035557, 0.05987896, 0.05940525, 0.05893444,\n",
       "       0.05846652, 0.05800147, 0.0575393 , 0.05707997, 0.05662349,\n",
       "       0.05616985, 0.05571903, 0.05527103, 0.05482582, 0.05438342,\n",
       "       0.05394379, 0.05350694, 0.05307286, 0.05264152, 0.05221293,\n",
       "       0.05178706, 0.05136392, 0.05094349, 0.05052575, 0.05011071,\n",
       "       0.04969834, 0.04928865, 0.0488816 , 0.04847721, 0.04807544,\n",
       "       0.04767631, 0.04727979, 0.04688587, 0.04649454, 0.0461058 ,\n",
       "       0.04571963, 0.04533602, 0.04495496, 0.04457644, 0.04420045,\n",
       "       0.04382697, 0.043456  , 0.04308753, 0.04272155, 0.04235804,\n",
       "       0.04199699, 0.0416384 , 0.04128224, 0.04092852, 0.04057723,\n",
       "       0.04022833, 0.03988184, 0.03953774, 0.03919602, 0.03885666,\n",
       "       0.03851966, 0.038185  , 0.03785268, 0.03752268, 0.037195  ,\n",
       "       0.03686962, 0.03654652, 0.03622571, 0.03590717, 0.03559089,\n",
       "       0.03527685, 0.03496506, 0.03465549, 0.03434813, 0.03404298,\n",
       "       0.03374003, 0.03343925, 0.03314065, 0.03284422, 0.03254993,\n",
       "       0.03225778, 0.03196777, 0.03167988, 0.03139409, 0.0311104 ,\n",
       "       0.0308288 , 0.03054927, 0.03027181, 0.02999641, 0.02972305,\n",
       "       0.02945173, 0.02918243, 0.02891514, 0.02864986, 0.02838656,\n",
       "       0.02812525, 0.02786591, 0.02760853, 0.0273531 , 0.02709961,\n",
       "       0.02684805, 0.02659841, 0.02635068, 0.02610484, 0.02586089,\n",
       "       0.02561882, 0.02537862, 0.02514027, 0.02490377, 0.0246691 ,\n",
       "       0.02443626, 0.02420524, 0.02397602, 0.02374859, 0.02352295,\n",
       "       0.02329909, 0.02307699, 0.02285664, 0.02263804, 0.02242117,\n",
       "       0.02220603, 0.0219926 , 0.02178088, 0.02157084, 0.0213625 ,\n",
       "       0.02115583, 0.02095082, 0.02074747, 0.02054576, 0.02034568,\n",
       "       0.02014724, 0.0199504 , 0.01975518, 0.01956154, 0.0193695 ,\n",
       "       0.01917903, 0.01899013, 0.01880278, 0.01861698, 0.01843272,\n",
       "       0.01824999, 0.01806878, 0.01788907, 0.01771087, 0.01753416,\n",
       "       0.01735893, 0.01718517, 0.01701287, 0.01684203, 0.01667263,\n",
       "       0.01650466, 0.01633812, 0.016173  , 0.01600928, 0.01584696,\n",
       "       0.01568603, 0.01552648, 0.0153683 , 0.01521149, 0.01505602,\n",
       "       0.0149019 , 0.01474911, 0.01459765, 0.01444751, 0.01429868,\n",
       "       0.01415114, 0.0140049 , 0.01385994, 0.01371625, 0.01357382,\n",
       "       0.01343266, 0.01329274, 0.01315405, 0.0130166 , 0.01288038,\n",
       "       0.01274536, 0.01261155, 0.01247894, 0.01234751, 0.01221727,\n",
       "       0.0120882 , 0.01196029, 0.01183354, 0.01170793, 0.01158346,\n",
       "       0.01146013, 0.01133791, 0.01121681, 0.01109682, 0.01097793,\n",
       "       0.01086013, 0.01074341, 0.01062776, 0.01051319, 0.01039967,\n",
       "       0.0102872 , 0.01017578, 0.0100654 , 0.00995604, 0.0098477 ,\n",
       "       0.00974038, 0.00963406, 0.00952875, 0.00942442, 0.00932108,\n",
       "       0.00921871, 0.00911731, 0.00901687, 0.00891739, 0.00881885,\n",
       "       0.00872126, 0.00862459, 0.00852885, 0.00843403, 0.00834012,\n",
       "       0.00824711, 0.008155  , 0.00806378, 0.00797345, 0.00788399,\n",
       "       0.0077954 , 0.00770767, 0.0076208 , 0.00753477, 0.00744959,\n",
       "       0.00736524, 0.00728173, 0.00719903, 0.00711715, 0.00703608,\n",
       "       0.00695581, 0.00687634, 0.00679766, 0.00671976, 0.00664264,\n",
       "       0.00656629, 0.0064907 , 0.00641587, 0.00634179, 0.00626846,\n",
       "       0.00619587, 0.00612401, 0.00605288, 0.00598247, 0.00591277,\n",
       "       0.00584378, 0.0057755 , 0.00570791, 0.00564102, 0.00557481,\n",
       "       0.00550928, 0.00544443, 0.00538024, 0.00531672, 0.00525385,\n",
       "       0.00519164, 0.00513007, 0.00506914, 0.00500884, 0.00494918,\n",
       "       0.00489014, 0.00483171, 0.0047739 , 0.0047167 , 0.0046601 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded['alphas_cumprod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasonx/Dropbox/repos/web-control-net/tinygrad/weights/sd-v1-4.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(74186) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "ram used:  4.26 GB, cond_stage_model.transformer.text_model.final_layer_norm.bias: 100%|██████████| 1131/1131 [00:06<00:00, 162.58it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights in 6975.22 ms, 4.26 GB loaded at 0.61 GB/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ram used:  5.71 GB, mid_block.resnets.1.conv2.bias                    : 100%|██████████| 340/340 [00:04<00:00, 81.01it/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights in 4200.28 ms, 5.71 GB loaded at 1.36 GB/s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "\n",
    "import argparse\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "from typing import Any, List, NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tinygrad.ops import Device\n",
    "from tinygrad.nn.state import load_state_dict, torch_load, get_state_dict, safe_save, safe_load_metadata\n",
    "from tinygrad.tensor import Tensor\n",
    "from extra.export_model import jit_model, compile_net\n",
    "\n",
    "from examples.stable_diffusion import (\n",
    "  StableDiffusion,\n",
    "  download_file,\n",
    ")\n",
    "from examples.controlnet import (\n",
    "  ControlNetUNetModel, \n",
    "  ControlNetModel, \n",
    "  ControlNetStableDiffusion\n",
    ")\n",
    "FILENAME_DIFFUSION = \"/Users/jasonx/Dropbox/repos/web-control-net/tinygrad/weights/sd-v1-4.ckpt\"\n",
    "FILENAME_CONTROLNET = \"/Users/jasonx/Dropbox/repos/web-control-net/tinygrad/weights/sd-controlnet-canny.bin\"\n",
    "print(FILENAME_DIFFUSION)\n",
    "download_file(\n",
    "'https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt', FILENAME_DIFFUSION)\n",
    "state_dict_diffusion = torch_load(FILENAME_DIFFUSION)[\"state_dict\"]\n",
    "diffusion_model = StableDiffusion()\n",
    "diffusion_model.model = namedtuple(\"DiffusionModel\", [\"diffusion_model\"])(\n",
    "diffusion_model=ControlNetUNetModel())\n",
    "load_state_dict(diffusion_model, state_dict_diffusion, strict=False)\n",
    "download_file(\n",
    "'https://huggingface.co/lllyasviel/sd-controlnet-canny/resolve/main/diffusion_pytorch_model.bin', FILENAME_CONTROLNET)\n",
    "state_dict_controlnet = torch_load(FILENAME_CONTROLNET)\n",
    "controlnet = ControlNetModel(cross_attention_dim=768)\n",
    "load_state_dict(controlnet, state_dict_controlnet, strict=False)\n",
    "\n",
    "model = ControlNetStableDiffusion(diffusion_model, controlnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = get_state_dict(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99915   , 0.998296  , 0.9974381 , 0.9965762 , 0.99571025,\n",
       "       0.9948404 , 0.9939665 , 0.9930887 , 0.9922069 , 0.9913211 ,\n",
       "       0.9904313 , 0.98953754, 0.9886398 , 0.9877381 , 0.9868324 ,\n",
       "       0.98592263, 0.98500896, 0.9840913 , 0.9831696 , 0.982244  ,\n",
       "       0.98131436, 0.9803808 , 0.97944313, 0.97850156, 0.977556  ,\n",
       "       0.9766064 , 0.97565293, 0.9746954 , 0.9737339 , 0.9727684 ,\n",
       "       0.97179896, 0.97082555, 0.96984816, 0.96886677, 0.9678814 ,\n",
       "       0.96689206, 0.96589875, 0.9649015 , 0.96390027, 0.9628951 ,\n",
       "       0.9618859 , 0.96087277, 0.95985574, 0.95883465, 0.9578097 ,\n",
       "       0.95678073, 0.95574784, 0.954711  , 0.95367026, 0.9526256 ,\n",
       "       0.9515769 , 0.95052433, 0.94946784, 0.94840735, 0.947343  ,\n",
       "       0.94627476, 0.9452025 , 0.9441264 , 0.9430464 , 0.9419625 ,\n",
       "       0.9408747 , 0.939783  , 0.9386874 , 0.93758786, 0.9364845 ,\n",
       "       0.93537724, 0.9342661 , 0.9331511 , 0.9320323 , 0.9309096 ,\n",
       "       0.929783  , 0.9286526 , 0.9275183 , 0.9263802 , 0.92523825,\n",
       "       0.92409253, 0.92294294, 0.9217895 , 0.92063236, 0.9194713 ,\n",
       "       0.9183065 , 0.9171379 , 0.91596556, 0.9147894 , 0.9136095 ,\n",
       "       0.91242576, 0.9112383 , 0.9100471 , 0.9088522 , 0.9076535 ,\n",
       "       0.9064511 , 0.90524495, 0.9040351 , 0.90282154, 0.9016043 ,\n",
       "       0.90038335, 0.8991587 , 0.8979304 , 0.8966984 , 0.89546275,\n",
       "       0.89422345, 0.8929805 , 0.89173394, 0.89048374, 0.88922995,\n",
       "       0.8879725 , 0.8867115 , 0.88544685, 0.88417864, 0.88290685,\n",
       "       0.8816315 , 0.88035256, 0.8790701 , 0.87778413, 0.8764946 ,\n",
       "       0.8752016 , 0.873905  , 0.87260497, 0.8713014 , 0.8699944 ,\n",
       "       0.86868393, 0.86737   , 0.8660526 , 0.8647318 , 0.86340755,\n",
       "       0.8620799 , 0.8607488 , 0.85941434, 0.8580765 , 0.8567353 ,\n",
       "       0.8553907 , 0.8540428 , 0.85269153, 0.85133696, 0.84997904,\n",
       "       0.84861785, 0.8472533 , 0.8458856 , 0.8445145 , 0.84314024,\n",
       "       0.84176266, 0.8403819 , 0.8389979 , 0.8376107 , 0.8362203 ,\n",
       "       0.83482677, 0.83343   , 0.8320301 , 0.8306271 , 0.8292209 ,\n",
       "       0.82781166, 0.82639927, 0.8249838 , 0.82356524, 0.8221436 ,\n",
       "       0.82071894, 0.81929123, 0.81786054, 0.8164268 , 0.8149901 ,\n",
       "       0.8135504 , 0.81210774, 0.81066215, 0.8092136 , 0.8077621 ,\n",
       "       0.80630773, 0.80485046, 0.8033903 , 0.80192727, 0.8004614 ,\n",
       "       0.79899275, 0.79752123, 0.7960469 , 0.7945698 , 0.7930899 ,\n",
       "       0.79160726, 0.7901219 , 0.7886338 , 0.787143  , 0.7856495 ,\n",
       "       0.7841533 , 0.78265446, 0.78115296, 0.7796488 , 0.77814204,\n",
       "       0.7766327 , 0.7751208 , 0.7736063 , 0.77208924, 0.7705697 ,\n",
       "       0.7690476 , 0.767523  , 0.7659959 , 0.7644664 , 0.76293445,\n",
       "       0.7614    , 0.7598632 , 0.75832397, 0.75678235, 0.75523835,\n",
       "       0.75369203, 0.7521434 , 0.75059247, 0.7490392 , 0.7474837 ,\n",
       "       0.7459259 , 0.7443659 , 0.74280363, 0.7412392 , 0.7396726 ,\n",
       "       0.7381038 , 0.73653287, 0.7349598 , 0.7333846 , 0.73180735,\n",
       "       0.730228  , 0.7286466 , 0.7270631 , 0.7254777 , 0.72389024,\n",
       "       0.72230077, 0.7207094 , 0.71911603, 0.7175208 , 0.7159236 ,\n",
       "       0.71432453, 0.7127236 , 0.71112084, 0.7095162 , 0.7079098 ,\n",
       "       0.7063016 , 0.70469165, 0.70307994, 0.7014665 , 0.69985133,\n",
       "       0.6982345 , 0.696616  , 0.6949958 , 0.69337404, 0.69175065,\n",
       "       0.69012564, 0.6884991 , 0.68687093, 0.6852413 , 0.68361014,\n",
       "       0.6819775 , 0.6803434 , 0.67870784, 0.6770708 , 0.6754324 ,\n",
       "       0.6737926 , 0.67215145, 0.670509  , 0.66886514, 0.66722   ,\n",
       "       0.6655736 , 0.66392595, 0.662277  , 0.6606269 , 0.65897554,\n",
       "       0.657323  , 0.65566933, 0.6540145 , 0.6523586 , 0.6507016 ,\n",
       "       0.6490435 , 0.64738435, 0.6457241 , 0.64406294, 0.6424008 ,\n",
       "       0.64073765, 0.63907355, 0.63740855, 0.6357426 , 0.6340758 ,\n",
       "       0.6324082 , 0.6307397 , 0.6290704 , 0.6274003 , 0.6257294 ,\n",
       "       0.62405777, 0.6223854 , 0.62071234, 0.6190386 , 0.61736417,\n",
       "       0.6156891 , 0.61401343, 0.6123372 , 0.6106603 , 0.6089829 ,\n",
       "       0.607305  , 0.6056265 , 0.6039476 , 0.60226816, 0.6005883 ,\n",
       "       0.598908  , 0.59722733, 0.5955463 , 0.59386486, 0.5921831 ,\n",
       "       0.59050107, 0.5888187 , 0.5871361 , 0.5854532 , 0.5837701 ,\n",
       "       0.5820868 , 0.5804033 , 0.5787197 , 0.5770359 , 0.575352  ,\n",
       "       0.57366806, 0.571984  , 0.5702999 , 0.5686158 , 0.56693166,\n",
       "       0.56524754, 0.5635635 , 0.5618795 , 0.56019557, 0.5585118 ,\n",
       "       0.5568281 , 0.55514455, 0.5534612 , 0.551778  , 0.5500951 ,\n",
       "       0.5484124 , 0.54673   , 0.5450478 , 0.54336596, 0.54168445,\n",
       "       0.54000324, 0.53832245, 0.5366421 , 0.53496206, 0.5332825 ,\n",
       "       0.53160346, 0.5299248 , 0.52824676, 0.5265692 , 0.52489215,\n",
       "       0.5232157 , 0.5215398 , 0.51986456, 0.51818997, 0.51651603,\n",
       "       0.51484275, 0.5131702 , 0.5114983 , 0.5098272 , 0.50815684,\n",
       "       0.5064873 , 0.50481856, 0.50315064, 0.50148356, 0.4998174 ,\n",
       "       0.4981521 , 0.49648774, 0.49482432, 0.49316183, 0.49150035,\n",
       "       0.48983985, 0.4881804 , 0.486522  , 0.48486462, 0.4832084 ,\n",
       "       0.48155323, 0.4798992 , 0.47824633, 0.47659463, 0.4749441 ,\n",
       "       0.47329482, 0.4716468 , 0.47      , 0.46835446, 0.46671024,\n",
       "       0.46506736, 0.4634258 , 0.46178558, 0.46014675, 0.45850933,\n",
       "       0.45687333, 0.45523876, 0.45360568, 0.45197406, 0.45034397,\n",
       "       0.44871536, 0.44708833, 0.44546285, 0.44383895, 0.44221666,\n",
       "       0.440596  , 0.43897697, 0.43735963, 0.43574396, 0.43412998,\n",
       "       0.43251774, 0.43090722, 0.4292985 , 0.42769152, 0.42608637,\n",
       "       0.42448303, 0.4228815 , 0.42128187, 0.4196841 , 0.41808826,\n",
       "       0.4164943 , 0.4149023 , 0.41331223, 0.41172415, 0.41013804,\n",
       "       0.40855396, 0.4069719 , 0.4053919 , 0.40381396, 0.4022381 ,\n",
       "       0.40066436, 0.39909273, 0.39752322, 0.3959559 , 0.39439073,\n",
       "       0.39282778, 0.39126703, 0.3897085 , 0.3881522 , 0.3865982 ,\n",
       "       0.38504648, 0.38349706, 0.38194993, 0.38040516, 0.37886274,\n",
       "       0.37732267, 0.375785  , 0.37424973, 0.37271687, 0.37118647,\n",
       "       0.36965853, 0.36813304, 0.36661002, 0.36508954, 0.36357155,\n",
       "       0.3620561 , 0.36054322, 0.3590329 , 0.35752517, 0.35602003,\n",
       "       0.35451752, 0.35301763, 0.3515204 , 0.3500258 , 0.3485339 ,\n",
       "       0.3470447 , 0.34555823, 0.34407446, 0.34259343, 0.34111515,\n",
       "       0.33963963, 0.33816692, 0.336697  , 0.3352299 , 0.33376563,\n",
       "       0.3323042 , 0.33084565, 0.32938993, 0.32793713, 0.3264872 ,\n",
       "       0.32504022, 0.32359615, 0.32215503, 0.32071686, 0.31928164,\n",
       "       0.31784943, 0.3164202 , 0.314994  , 0.3135708 , 0.31215066,\n",
       "       0.31073356, 0.3093195 , 0.30790854, 0.30650064, 0.30509588,\n",
       "       0.30369422, 0.30229566, 0.30090025, 0.299508  , 0.2981189 ,\n",
       "       0.29673296, 0.29535022, 0.2939707 , 0.29259437, 0.29122123,\n",
       "       0.28985137, 0.28848472, 0.28712133, 0.2857612 , 0.28440437,\n",
       "       0.2830508 , 0.28170055, 0.2803536 , 0.27900997, 0.27766964,\n",
       "       0.27633268, 0.27499905, 0.2736688 , 0.27234194, 0.27101842,\n",
       "       0.2696983 , 0.26838157, 0.26706827, 0.26575837, 0.26445192,\n",
       "       0.26314887, 0.2618493 , 0.26055318, 0.2592605 , 0.25797132,\n",
       "       0.2566856 , 0.2554034 , 0.25412467, 0.25284946, 0.25157773,\n",
       "       0.2503096 , 0.24904492, 0.24778382, 0.24652626, 0.24527225,\n",
       "       0.2440218 , 0.24277493, 0.24153163, 0.24029191, 0.23905578,\n",
       "       0.23782326, 0.23659433, 0.23536903, 0.23414734, 0.23292927,\n",
       "       0.23171483, 0.23050404, 0.22929688, 0.22809339, 0.22689353,\n",
       "       0.22569734, 0.22450483, 0.22331597, 0.2221308 , 0.22094932,\n",
       "       0.21977153, 0.21859743, 0.21742703, 0.21626033, 0.21509734,\n",
       "       0.21393807, 0.21278252, 0.21163069, 0.21048258, 0.20933822,\n",
       "       0.20819758, 0.2070607 , 0.20592754, 0.20479813, 0.20367248,\n",
       "       0.20255059, 0.20143245, 0.20031808, 0.19920748, 0.19810064,\n",
       "       0.19699757, 0.19589828, 0.19480278, 0.19371104, 0.1926231 ,\n",
       "       0.19153893, 0.19045855, 0.18938197, 0.18830918, 0.18724018,\n",
       "       0.18617497, 0.18511358, 0.18405597, 0.18300217, 0.18195218,\n",
       "       0.18090598, 0.1798636 , 0.17882504, 0.17779027, 0.1767593 ,\n",
       "       0.17573217, 0.17470883, 0.1736893 , 0.1726736 , 0.1716617 ,\n",
       "       0.17065361, 0.16964935, 0.1686489 , 0.16765225, 0.16665943,\n",
       "       0.16567042, 0.16468522, 0.16370384, 0.16272627, 0.16175252,\n",
       "       0.16078258, 0.15981644, 0.15885411, 0.1578956 , 0.15694089,\n",
       "       0.15599   , 0.15504292, 0.15409963, 0.15316014, 0.15222447,\n",
       "       0.15129258, 0.1503645 , 0.14944021, 0.14851972, 0.14760303,\n",
       "       0.14669013, 0.14578101, 0.14487568, 0.14397413, 0.14307636,\n",
       "       0.14218238, 0.14129217, 0.14040573, 0.13952307, 0.13864417,\n",
       "       0.13776903, 0.13689767, 0.13603005, 0.13516618, 0.13430607,\n",
       "       0.13344972, 0.1325971 , 0.13174823, 0.1309031 , 0.13006169,\n",
       "       0.12922402, 0.12839006, 0.12755983, 0.12673332, 0.12591052,\n",
       "       0.12509143, 0.12427604, 0.12346435, 0.12265636, 0.12185206,\n",
       "       0.12105144, 0.1202545 , 0.11946124, 0.11867165, 0.11788572,\n",
       "       0.11710346, 0.11632485, 0.11554988, 0.11477857, 0.11401089,\n",
       "       0.11324684, 0.11248643, 0.11172963, 0.11097645, 0.11022688,\n",
       "       0.10948092, 0.10873855, 0.10799977, 0.10726459, 0.10653298,\n",
       "       0.10580494, 0.10508047, 0.10435956, 0.1036422 , 0.10292839,\n",
       "       0.10221813, 0.1015114 , 0.10080819, 0.1001085 , 0.09941233,\n",
       "       0.09871966, 0.0980305 , 0.09734483, 0.09666264, 0.09598393,\n",
       "       0.09530868, 0.09463691, 0.09396859, 0.09330372, 0.09264228,\n",
       "       0.09198428, 0.09132971, 0.09067855, 0.0900308 , 0.08938646,\n",
       "       0.0887455 , 0.08810794, 0.08747375, 0.08684293, 0.08621547,\n",
       "       0.08559138, 0.08497062, 0.08435319, 0.0837391 , 0.08312833,\n",
       "       0.08252087, 0.08191671, 0.08131585, 0.08071827, 0.08012398,\n",
       "       0.07953294, 0.07894517, 0.07836065, 0.07777938, 0.07720133,\n",
       "       0.07662651, 0.07605491, 0.07548651, 0.07492131, 0.0743593 ,\n",
       "       0.07380046, 0.0732448 , 0.07269229, 0.07214294, 0.07159673,\n",
       "       0.07105365, 0.0705137 , 0.06997685, 0.06944311, 0.06891247,\n",
       "       0.06838491, 0.06786042, 0.06733901, 0.06682064, 0.06630533,\n",
       "       0.06579305, 0.0652838 , 0.06477757, 0.06427433, 0.0637741 ,\n",
       "       0.06327686, 0.06278259, 0.06229129, 0.06180295, 0.06131756,\n",
       "       0.0608351 , 0.06035557, 0.05987896, 0.05940525, 0.05893444,\n",
       "       0.05846652, 0.05800147, 0.0575393 , 0.05707997, 0.05662349,\n",
       "       0.05616985, 0.05571903, 0.05527103, 0.05482582, 0.05438342,\n",
       "       0.05394379, 0.05350694, 0.05307286, 0.05264152, 0.05221293,\n",
       "       0.05178706, 0.05136392, 0.05094349, 0.05052575, 0.05011071,\n",
       "       0.04969834, 0.04928865, 0.0488816 , 0.04847721, 0.04807544,\n",
       "       0.04767631, 0.04727979, 0.04688587, 0.04649454, 0.0461058 ,\n",
       "       0.04571963, 0.04533602, 0.04495496, 0.04457644, 0.04420045,\n",
       "       0.04382697, 0.043456  , 0.04308753, 0.04272155, 0.04235804,\n",
       "       0.04199699, 0.0416384 , 0.04128224, 0.04092852, 0.04057723,\n",
       "       0.04022833, 0.03988184, 0.03953774, 0.03919602, 0.03885666,\n",
       "       0.03851966, 0.038185  , 0.03785268, 0.03752268, 0.037195  ,\n",
       "       0.03686962, 0.03654652, 0.03622571, 0.03590717, 0.03559089,\n",
       "       0.03527685, 0.03496506, 0.03465549, 0.03434813, 0.03404298,\n",
       "       0.03374003, 0.03343925, 0.03314065, 0.03284422, 0.03254993,\n",
       "       0.03225778, 0.03196777, 0.03167988, 0.03139409, 0.0311104 ,\n",
       "       0.0308288 , 0.03054927, 0.03027181, 0.02999641, 0.02972305,\n",
       "       0.02945173, 0.02918243, 0.02891514, 0.02864986, 0.02838656,\n",
       "       0.02812525, 0.02786591, 0.02760853, 0.0273531 , 0.02709961,\n",
       "       0.02684805, 0.02659841, 0.02635068, 0.02610484, 0.02586089,\n",
       "       0.02561882, 0.02537862, 0.02514027, 0.02490377, 0.0246691 ,\n",
       "       0.02443626, 0.02420524, 0.02397602, 0.02374859, 0.02352295,\n",
       "       0.02329909, 0.02307699, 0.02285664, 0.02263804, 0.02242117,\n",
       "       0.02220603, 0.0219926 , 0.02178088, 0.02157084, 0.0213625 ,\n",
       "       0.02115583, 0.02095082, 0.02074747, 0.02054576, 0.02034568,\n",
       "       0.02014724, 0.0199504 , 0.01975518, 0.01956154, 0.0193695 ,\n",
       "       0.01917903, 0.01899013, 0.01880278, 0.01861698, 0.01843272,\n",
       "       0.01824999, 0.01806878, 0.01788907, 0.01771087, 0.01753416,\n",
       "       0.01735893, 0.01718517, 0.01701287, 0.01684203, 0.01667263,\n",
       "       0.01650466, 0.01633812, 0.016173  , 0.01600928, 0.01584696,\n",
       "       0.01568603, 0.01552648, 0.0153683 , 0.01521149, 0.01505602,\n",
       "       0.0149019 , 0.01474911, 0.01459765, 0.01444751, 0.01429868,\n",
       "       0.01415114, 0.0140049 , 0.01385994, 0.01371625, 0.01357382,\n",
       "       0.01343266, 0.01329274, 0.01315405, 0.0130166 , 0.01288038,\n",
       "       0.01274536, 0.01261155, 0.01247894, 0.01234751, 0.01221727,\n",
       "       0.0120882 , 0.01196029, 0.01183354, 0.01170793, 0.01158346,\n",
       "       0.01146013, 0.01133791, 0.01121681, 0.01109682, 0.01097793,\n",
       "       0.01086013, 0.01074341, 0.01062776, 0.01051319, 0.01039967,\n",
       "       0.0102872 , 0.01017578, 0.0100654 , 0.00995604, 0.0098477 ,\n",
       "       0.00974038, 0.00963406, 0.00952875, 0.00942442, 0.00932108,\n",
       "       0.00921871, 0.00911731, 0.00901687, 0.00891739, 0.00881885,\n",
       "       0.00872126, 0.00862459, 0.00852885, 0.00843403, 0.00834012,\n",
       "       0.00824711, 0.008155  , 0.00806378, 0.00797345, 0.00788399,\n",
       "       0.0077954 , 0.00770767, 0.0076208 , 0.00753477, 0.00744959,\n",
       "       0.00736524, 0.00728173, 0.00719903, 0.00711715, 0.00703608,\n",
       "       0.00695581, 0.00687634, 0.00679766, 0.00671976, 0.00664264,\n",
       "       0.00656629, 0.0064907 , 0.00641587, 0.00634179, 0.00626846,\n",
       "       0.00619587, 0.00612401, 0.00605288, 0.00598247, 0.00591277,\n",
       "       0.00584378, 0.0057755 , 0.00570791, 0.00564102, 0.00557481,\n",
       "       0.00550928, 0.00544443, 0.00538024, 0.00531672, 0.00525385,\n",
       "       0.00519164, 0.00513007, 0.00506914, 0.00500884, 0.00494918,\n",
       "       0.00489014, 0.00483171, 0.0047739 , 0.0047167 , 0.0046601 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state['alphas_cumprod'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webgpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
